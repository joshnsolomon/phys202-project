{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import integrate\n",
    "from IPython.html.widgets import interact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "print(digits.data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Neural Network "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose is this project is to explain the basics of neural networks and use one to read handwriting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Neural Network is a type of program that can trained to perform very complicated functions. It does this by creating a network of \"neurons\" that can be used to interpret informations. Below is a picture of one such neuron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARgAAACKCAQAAADbXp37AAAABGdBTUEAALGPC/xhBQAAACBjSFJN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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image('tikz9.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each Neuron has an input vector and weights assigned to each component as well as a bias. It then runs the sum through a Sigmoid funnction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "\\sigma(x) = \\frac{1}{1+e^{-x}} \\\\\n",
    "Output = \\sigma(\\vec{w} \\cdot \\vec{x}+b)\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPYAAAD7CAYAAABZjGkWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAADIpJREFUeJzt3V2MXVUZxvHnaQtpC9oWIYJSoBdA8AoabUQ+HLQQIBUT\nYgJNCEKDV/IRJUY0QDoJCZdiYryhQKgWTKjWUBFBoeUjRcpHayttiRBIhvJhkzYV25CAvF7MLk6G\nsbPnnL3WdN7+f8mkZ2bO7PedZp6z9jlnrb0cEQKQy7TJbgBA9wg2kBDBBhIi2EBCBBtIiGADCU1K\nsG1fbHuH7X/Y/nHhWvfafs/21pJ1RtSbb3ud7Vds/932jYXrzbT9vO3NtrfZvrNkvabmdNubbK8t\nXaup96btLU3NjYVrzbW92vb25v/zqwVrnd78Tgc+9nb29xIRVT8kTZf0mqRTJB0habOkMwrWO0/S\nWZK2Vvr9jpd0ZnP7aEmvlvz9mjqzm39nSPqrpHML1/uhpFWSHq70f/qGpGMq1bpf0rIR/59zKtWd\nJukdSfO7ON5kjNiLJL0WEW9GxIeSfiPp26WKRcQzkvaUOv4Y9d6NiM3N7X9L2i7pC4Vr7m9uHqnh\nB87dpWrZPlHSpZJWSHKpOmOVLl7AniPpvIi4V5Ii4qOI2Fu6bmOxpNcjYqiLg01GsL8oaWTzbzVf\nS8f2KRo+W3i+cJ1ptjdLek/SuojYVrDczyT9SNLHBWuMFpL+YvtF298rWGeBpF2277P9su27bc8u\nWG+kKyU90NXBJiPYh8UcVttHS1ot6aZm5C4mIj6OiDMlnSjpfNsDJerYXiLpnxGxSXVH63Mi4ixJ\nl0j6vu3zCtWZIWmhpF9GxEJJ+yTdUqjWJ2wfKelbkh7q6piTEeydkuaP+Hy+hkftNGwfIem3kn4d\nEb+vVbc5bXxE0pcLlfiapMtsvyHpQUnfsL2yUK1PRMQ7zb+7JK3R8NO5Et6S9FZEvNB8vlrDQS/t\nEkkvNb9fJyYj2C9KOtX2Kc0j1RWSHp6EPoqwbUn3SNoWEXdVqHes7bnN7VmSLpS0qUStiPhpRMyP\niAUaPnV8MiKuLlHrANuzbX+muX2UpIskFXmHIyLelTRk+7TmS4slvVKi1ihLNfxA2ZkZXR6sjYj4\nyPb1kh7T8As990TE9lL1bD8o6euSPmd7SNLtEXFfqXqSzpF0laQttg8E7CcR8adC9U6QdL/taRp+\noP5VRDxRqNZoNZ5WfV7SmuHHS82QtCoiHi9Y7wZJq5pB53VJ1xasdeDBarGkTl87cPNSO4BEmHkG\nJESwgYQINpAQwQYSIthAQn2/3WWbl9WBSRQRn5oF2Mn72L28ZbZ8+XItX768i/JF6z333HM91Vux\nYoWuu+66Cf/csmXLeqq3a9cuHXfccRP+ucsvv7ynek8//bTOP//8nn72tttum/DP3HHHHbr11lt7\nqjdz5swJ/8xU+fts3t//FE7FgYQINpDQpAV7YGAgdb2FC2usHfif2bNrrS4cdvLJJ1et1+tpf6+m\n+t9n31NKbUfmaam9PsfuVa/PsXvV63PsfvTyHLsfvTzHnipsj/niGafiQEIEG0iIYAMJjRvsmpcK\nBtCNgwbb9nRJv5B0saQvSVpq+4wajQHo3XgjdtVLBQPoxnjBPmwuFQxkMl6w875BDSQ23iKQVpcK\nHjl5fWBgoPqsHeBwsX79eq1fv37c+x105pntGRree+qbkt6WtFHS0pFXFWXmWbeYeda9w3Hm2UFH\n7NqXCgbQjXHXY0fEo5IerdALgI4w8wxIiGADCRFsICGCDSREsIGECDaQEMEGEiLYQEIEG0iok51A\nMqs9d3vHjh1V6+3evbtqPUmaNWtW1XobNmyoWu/ss8+uWm8sjNhAQgQbSIhgAwkRbCAhgg0kRLCB\nhAg2kBDBBhIi2EBCbfbuutf2e7a31mgIQP/ajNj3aXjvLgBTxLjBjohnJO2p0AuAjvAcG0iok9Vd\nbPED1NF2i5/Ogw2gnNED5+Dg4Jj341QcSKjN210PStog6TTbQ7avLd8WgH602btraY1GAHSHU3Eg\nIYINJESwgYQINpAQwQYSIthAQgQbSIhgAwkRbCChKbd319DQUNV62ffSmjdvXtV6Uv3fkb27AKRA\nsIGECDaQEMEGEiLYQEIEG0iIYAMJEWwgIYINJNTmYobzba+z/Yrtv9u+sUZjAHrXZkrph5J+EBGb\nbR8t6SXbf46I7YV7A9CjNnt3vRsRm5vb/5a0XdIXSjcGoHcTeo5t+xRJZ0l6vkQzALrRenVXcxq+\nWtJNzcj9CfbuAupou3eXI2L8O9lHSPqDpEcj4q5R34s2x+hK7WWbJ510UtV6h8OyzSuuuKJqvUWL\nFlWtd/PNN1erZVsR4dFfb/OquCXdI2nb6FADODS1eY59jqSrJF1ge1PzcXHhvgD0oc3eXc+KiSzA\nlEJggYQINpAQwQYSIthAQgQbSIhgAwkRbCAhgg0kRLCBhKbc3l3vv/9+1Xq1V6pNxqKM2movyjgc\nMWIDCRFsICGCDSREsIGECDaQEMEGEiLYQEIEG0iIYAMJtblK6Uzbz9vebHub7TtrNAagd20uZviB\n7QsiYr/tGZKetX1uc5FDAIegVqfiEbG/uXmkpOmS6l7VHsCEtAq27Wm2N0t6T9K6iNhWti0A/Wi1\nuisiPpZ0pu05kh6zPRAR6w98n727gDra7t01oWWbEbHX9iOSvizpk6OPDDaAckYPnIODg2Per82r\n4sfantvcniXpQkmbOukSQBFtRuwTJN1ve5qGHwh+FRFPlG0LQD/avN21VdLCCr0A6Agzz4CECDaQ\nEMEGEiLYQEIEG0iIYAMJEWwgIYINJESwgYSm3N5de/furVpvyZIlVesdDnbvrruc/5hjjqla71DA\niA0kRLCBhAg2kBDBBhIi2EBCBBtIiGADCRFsICGCDSTUdsOA6bY32V5buiEA/Ws7Yt8kaZukKNgL\ngI60ua74iZIulbRCkot3BKBvbUbsn0n6kaSPC/cCoCMHXd1le4mkf0bEJtsD/+9+7N0F1NHV3l1f\nk3SZ7UslzZT0WdsrI+LqkXdi7y6gjk727oqIn0bE/IhYIOlKSU+ODjWAQ89E38fmVXFgCmh9BZWI\neErSUwV7AdARZp4BCRFsICGCDSREsIGECDaQEMEGEiLYQEIEG0iIYAMJTbm9u+bMmVO13saNG6vW\nq+2DDz6oXnPDhg1V611zzTVV6x0KGLGBhAg2kBDBBhIi2EBCBBtIiGADCRFsICGCDSREsIGEWs08\ns/2mpH9J+o+kDyNiUcmmAPSn7ZTSkDQQEbtLNgOgGxM5FWffLmCKaBvskPQX2y/a/l7JhgD0r+2p\n+DkR8Y7t4yT92faOiHjmwDfZuwuoo6u9uyRJEfFO8+8u22skLZI0ZrABlNPJ3l2SZHu27c80t4+S\ndJGkrZ10CaCINiP25yWtsX3g/qsi4vGiXQHoy7jBjog3JJ1ZoRcAHWHmGZAQwQYSIthAQgQbSIhg\nAwkRbCAhgg0kRLCBhAg2kJAjor8D2NHvMSZiz5491WpJ0qmnnlq13tq1a6vWW7lyZdV6krRjx46q\n9datW1e1Xk22FRGfulYCIzaQEMEGEiLYQEIEG0iIYAMJEWwgIYINJESwgYQINpBQm6uUzrW92vZ2\n29tsf7VGYwB61+YqpT+X9MeI+I7tGZKOKtwTgD4dNNi250g6LyK+K0kR8ZGkvTUaA9C78U7FF0ja\nZfs+2y/bvtv27BqNAejdeKfiMyQtlHR9RLxg+y5Jt0i6feSd2LsLqKPt3l0HXbZp+3hJz0XEgubz\ncyXdEhFLRtyHZZsdYtlm91i2OUpEvCtpyPZpzZcWS3qlQH8AOtTmVfEbJK2yfaSk1yVdW7YlAP1q\ns3fX3yR9pUIvADrCzDMgIYINJESwgYQINpAQwQYSIthAQgQbSIhgAwkRbCChNlNKDynz5s2rWq/2\nIolly5ZVrTcZK/EyL8o4VDBiAwkRbCAhgg0kRLCBhAg2kBDBBhIi2EBCBBtIqM0WP6fb3jTiY6/t\nG2s0B6A3ba559qqksyTJ9jRJOyWtKdwXgD5M9FR8saTXI2KoRDMAujHRYF8p6YESjQDoTutgN9cV\n/5akh8q1A6ALE1nddYmklyJi1+hvsHcXUEfbvbsmEuylkh4c6xsjgw2gnNED5+Dg4Jj3a3Uqbvso\nDb9w9rsOegNQWKsROyL2STq2cC8AOsLMMyAhgg0kRLCBhAg2kBDBBhIi2EBCkxbsNrNnpnK9LVu2\nVK23b9++qvV27txZtV72v5eu6xHsQrZu3Vq13v79+6vWe/vtt6vWy/73kibYAMoh2EBCjoj+DmD3\ndwAAfYkIj/5a38EGcOjhVBxIiGADCRFsICGCDSREsIGE/gsqZOqagjaRxQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f929a9627f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_digit(i):\n",
    "    plt.matshow(digits.images[i],cmap = 'Greys');\n",
    "    \n",
    "interact(show_digit, i=(0,100));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sigm(z):\n",
    "    return 1/(1+np.e**(-1*z))\n",
    "sigm_vec = np.vectorize(sigm)\n",
    "\n",
    "def sigm_prime(z):\n",
    "    return sigm(z)*(1-sigm(z))\n",
    "sigm_prime_vec = np.vectorize(sigm_prime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Network(object):\n",
    "    def __init__(self, sizes):\n",
    "        np.random.seed(0)\n",
    "        self.sizes = sizes\n",
    "        self.layers = len(sizes)\n",
    "        self.biases = [np.random.randn(y, 1) for y in sizes[1:]]\n",
    "        self.weights = [np.random.randn(y, x) for x, y in zip(sizes[:-1], sizes[1:])]\n",
    "        \n",
    "    def feedforward(self,a):\n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            a = sigm_vec(np.dot(w, a) + b)\n",
    "        return a\n",
    "    \n",
    "    def SGD( self, training_data, epochs, mini_batch_size, eta):\n",
    "        np.random.seed(0)\n",
    "        n = len(training_data)\n",
    "        for j in range(epochs):\n",
    "            np.random.shuffle(training_data)\n",
    "            mini_batches = [\n",
    "                training_data[k:k+mini_batch_size]\n",
    "                for k in range(0, n, mini_batch_size)]\n",
    "            for mini_batch in mini_batches:\n",
    "                self.update_mini_batch(mini_batch, eta)\n",
    "    \n",
    "    def update_mini_batch(self, mini_batch, eta):\n",
    "        grad_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        grad_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        for x, y in mini_batch:\n",
    "            delta_grad_b, delta_grad_w = self.backprop(x, y)\n",
    "            grad_b = [nb+dnb for nb, dnb in zip(grad_b, delta_grad_b)]\n",
    "            grad_w = [nw+dnw for nw, dnw in zip(grad_w, delta_grad_w)]\n",
    "        self.weights = [w-(eta/len(mini_batch))*gw \n",
    "                        for w, gw in zip(self.weights, grad_w)]\n",
    "        self.biases = [b-(eta/len(mini_batch))*gb \n",
    "                       for b, gb in zip(self.biases, grad_b)]\n",
    "        \n",
    "    def backprop(self,x,y):\n",
    "        grad_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        grad_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        activation = x\n",
    "        activations = [x] \n",
    "        zs = [] \n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            z = np.dot(w, activation)+b\n",
    "            zs.append(z)\n",
    "            activation = sigm_vec(z)\n",
    "            activations.append(activation)\n",
    "        delta = (activations[-1] - y) * sigm_prime_vec(zs[-1])\n",
    "        grad_b[-1] = delta\n",
    "        grad_w[-1] = np.dot(delta, activations[-2].T)\n",
    "        for a in range(2, self.layers):\n",
    "            z = zs[-a]\n",
    "            spv = sigm_prime_vec(z)\n",
    "            delta = np.dot(self.weights[-a+1].T, delta) * spv\n",
    "            grad_b[-a] = delta\n",
    "            grad_w[-a] = np.dot(delta, activations[-a-1].T)\n",
    "        return (grad_b, grad_w)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def vector(a):\n",
    "    v = np.array([[0.,0.,0.,0.,0.,0.,0.,0.,0.,0.]])\n",
    "    v[0][a]=1\n",
    "    return v.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "digits.target[0:700]\n",
    "training_set = [(np.array([x]).T,np.array([vectorize(y)]).T) for x, y in zip(digits.data[0:700],digits.target[0:700])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Reader = Network([64,37,10])\n",
    "Reader.SGD(training_set,70,10,1.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percent: 0.9123287671232877\n"
     ]
    }
   ],
   "source": [
    "right = 0\n",
    "wrong = 0\n",
    "for b in np.random.permutation(range(701,1796)):\n",
    "    a = np.array([digits.data[b]]).T\n",
    "    if digits.target[b] == np.argmax(Reader.feedforward(a)):\n",
    "        right += 1\n",
    "    else:\n",
    "        wrong +=1\n",
    "percent = (float(right)/(right+wrong))\n",
    "print('percent: '+ str(percent))\n",
    "            \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
