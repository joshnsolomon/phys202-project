{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import integrate\n",
    "from IPython.html.widgets import interact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "print(digits.data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Neural Network "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose is this project is to explain the basics of neural networks and use one to read handwriting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Neural Network is a type of program that can trained to perform very complicated functions. It does this by creating a network of \"neurons\" that can be used to interpret informations. Below is a picture of one such neuron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARgAAACKCAQAAADbXp37AAAABGdBTUEAALGPC/xhBQAAACBjSFJN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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image('tikz9.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each Neuron has an input vector and weights assigned to each component as well as a bias. It then runs the sum through a Sigmoid funnction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "\\sigma(x) = \\frac{1}{1+e^{-x}} \\\\\n",
    "Output = \\sigma(\\vec{w} \\cdot \\vec{x}+b)\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPYAAAD7CAYAAABZjGkWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f929a8870f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_digit(i):\n",
    "    plt.matshow(digits.images[i],cmap = 'Greys');\n",
    "    \n",
    "interact(show_digit, i=(0,100));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sigm(z):\n",
    "    return 1/(1+np.e**(-1*z))\n",
    "sigm_vec = np.vectorize(sigm)\n",
    "\n",
    "def sigm_prime(z):\n",
    "    return sigm(z)*(1-sigm(z))\n",
    "sigm_prime_vec = np.vectorize(sigm_prime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Network(object):\n",
    "    def __init__(self, sizes):\n",
    "        np.random.seed(0)\n",
    "        self.sizes = sizes\n",
    "        self.layers = len(sizes)\n",
    "        self.biases = [np.random.randn(y, 1) for y in sizes[1:]]\n",
    "        self.weights = [np.random.randn(y, x) for x, y in zip(sizes[:-1], sizes[1:])]\n",
    "        \n",
    "    def feedforward(self,a):\n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            a = sigm_vec(np.dot(w, a) + b)\n",
    "        return a\n",
    "    \n",
    "    def SGD( self, training_data, epochs, mini_batch_size, eta):\n",
    "        np.random.seed(0)\n",
    "        n = len(training_data)\n",
    "        for j in range(epochs):\n",
    "            np.random.shuffle(training_data)\n",
    "            mini_batches = [\n",
    "                training_data[k:k+mini_batch_size]\n",
    "                for k in range(0, n, mini_batch_size)]\n",
    "            for mini_batch in mini_batches:\n",
    "                self.update_mini_batch(mini_batch, eta)\n",
    "    \n",
    "    def update_mini_batch(self, mini_batch, eta):\n",
    "        grad_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        grad_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        for x, y in mini_batch:\n",
    "            delta_grad_b, delta_grad_w = self.backprop(x, y)\n",
    "            grad_b = [nb+dnb for nb, dnb in zip(grad_b, delta_grad_b)]\n",
    "            grad_w = [nw+dnw for nw, dnw in zip(grad_w, delta_grad_w)]\n",
    "        self.weights = [w-(eta/len(mini_batch))*gw \n",
    "                        for w, gw in zip(self.weights, grad_w)]\n",
    "        self.biases = [b-(eta/len(mini_batch))*gb \n",
    "                       for b, gb in zip(self.biases, grad_b)]\n",
    "        \n",
    "    def backprop(self,x,y):\n",
    "        grad_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        grad_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        activation = x\n",
    "        activations = [x] \n",
    "        zs = [] \n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            z = np.dot(w, activation)+b\n",
    "            zs.append(z)\n",
    "            activation = sigm_vec(z)\n",
    "            activations.append(activation)\n",
    "        delta = (activations[-1] - y) * sigm_prime_vec(zs[-1])\n",
    "        grad_b[-1] = delta\n",
    "        grad_w[-1] = np.dot(delta, activations[-2].T)\n",
    "        for a in range(2, self.layers):\n",
    "            z = zs[-a]\n",
    "            spv = sigm_prime_vec(z)\n",
    "            delta = np.dot(self.weights[-a+1].T, delta) * spv\n",
    "            grad_b[-a] = delta\n",
    "            grad_w[-a] = np.dot(delta, activations[-a-1].T)\n",
    "        return (grad_b, grad_w)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def vector(a):\n",
    "    v = np.array([[0.,0.,0.,0.,0.,0.,0.,0.,0.,0.]])\n",
    "    v[0][a]=1\n",
    "    return v.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "digits.target[0:700]\n",
    "training_set = [(np.array([x]).T,np.array([vectorize(y)]).T) for x, y in zip(digits.data[0:700],digits.target[0:700])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Reader = Network([64,37,10])\n",
    "Reader.SGD(training_set,70,10,1.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percent: 0.9123287671232877\n"
     ]
    }
   ],
   "source": [
    "right = 0\n",
    "wrong = 0\n",
    "for b in np.random.permutation(range(701,1796)):\n",
    "    a = np.array([digits.data[b]]).T\n",
    "    if digits.target[b] == np.argmax(Reader.feedforward(a)):\n",
    "        right += 1\n",
    "    else:\n",
    "        wrong +=1\n",
    "percent = (float(right)/(right+wrong))\n",
    "print('percent: '+ str(percent))\n",
    "            \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
